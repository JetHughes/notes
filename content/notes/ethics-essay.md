# Misinformation and the Wellington Protests
Jet Hughes 9474308

# Intro
As members of society, we must consider the ethical implications of our actions and inactions. This extends to our private lives, and our work. As members of the IT profession, we have an obligation to adhere to certain standards. These have been collated and formalised into the ACM Code of Ethics [^0]. This Code "expresses the conscience of the profession", putting human well-being as the main focus. Although it provides a guideline for us to follow, it is not specific to everyone and should merely act as a foundation for individuals, businesses, and governments to build upon. 

The recent outbreak of misinformation and censorship, culminating in Aotearoa with the convoy and the Wellington protest in February and March this year, provides an interesting avenue through which we can analyse the spread of information through online channels, and the impact of the computing profession. Many businesses in the computing sector were key components of the event. For example, Facebook, Gab and Telegram, as well as stuff.co.nz and other news outlets. These organisations have an inherent obligation to consider how their platforms are being used to encourage or discourage the spread of information, regardless of its source and credibility. 

I do not have the knowledge or experience to make an informed decision about what should be allowed on large platforms such as Spotify, Facebook, and YouTube. However, I am able to give my opinion about how misinformation, censorship, and freedom of expression should be balanced. This essay will examine the point of view of the protesters at Wellington and contrast it with Stuff's Fire and Fury in an attempt to learn more about how to balance censorship and freedom of expression in an online world. 

# 1 - River of Filth
Throughout history, we can observe countless instances of delayed acceptance of medical discoveries. Even the process of resuscitation through mouth-to-mouth breathing and chest compressions was initially rejected by the public and discouraged [^1]. Anti-Vaccination movements existed long before the Covid-19 pandemic. Ever since the first vaccinations, REF people have felt uncomfortable. Shorty before Covid-19 struck, Anti Vaccination supporters protested against the MMR and Measles vaccines. However, following the announcement of the Covid-19 vaccine, these groups gained more followers and started to spread their views, which eventually led to the convoy and the Wellington protests [^2]. They documented their journey in the video titled River of Filth. The video starts with news and articles where the NZ government stated that the vaccine would not be mandatory. Next, they depict the government's betrayal of this promise, forcing 40% of the NZ workforce to be vaccinated. They then showed footage of the convoy, various protests along the way, and the camp out at Wellington parliament. The video then finishes with a message condemning the government and mainstream media, and praising the protesters and their efforts. After 23 days the protesters were forcefully and violently removed more than 100 police, 87 protesters were arrested, and 50 vehicles towed [^3][^4]. The protesters were mostly protesting the NZ government Covid-19 response, including mask mandates, vaccine mandates and lockdowns[^2]. However, various anti-establishment and/or anti-mainstream media groups were also present, many of which were calling for trials and executions. 

This protest is part of a worldwide trend, an "epidemic of misinformation" [^5]. The protests spawned from online campaigns and pre-existing fringe groups who found a common cause [^6]. Online platforms such as Facebook, Instagram, TikTok, Gab and Telegram facilitated the formation and propagation of these groups and various other protests [^6]. They enabled the protesters to reach a large audience, spread their agenda and influence the public. One of the most prominent organisations, Voices for Freedom (VFF) were banned from Facebook, and were able to successfully migrate to other, more lenient platforms such as Gab and Telegram [^7]. They deployed techniques similar to fascist strategies, such as "flooding the zone" and trying to "swarm social media". They asked for assistance from long-standing members of the anti-vax community who gave advice such as giving the people "an alternative narrative", a strategy used to refute the Flu and MMR vaccines. 

The role of the IT sector in the Wellington protests is clearly a significant one. Without the platforms mentioned, the protest could have likely never happened. However, the eradication of these platforms is not a solution. What we can do, however, is try to balance and regulate the spread of misinformation on these platforms. But we must be careful in doing so, as people have a right to free speech. How can we balance censorship and freedom of expression on platform such as these? 

# 2 - Fire and Fury
The documentary Fire and Fury created by a team of journalists from Stuff.co.nz, investigating the Wellington protests, what caused them, and some of the key people behind the protests. It showed the progress of the movement leading up to the occupation [^7]. The documentary received mixed reviews and a very low score of 3.9/10 from IMDB [^8]. An in-house review by stuff praised it as "journalism at the peak of its powers" [^9], while others have said it "veers into the absurd" [^9]. Of course, each of these third parties have biases of their own which must be taken into account. Everyone online is able to present themselves however they like, and masquerade as something they are not. It is incredibly difficult to separate the good from the bad. 

The stuff article praising the documentary [^9] says the team behind it "interviewed the right people", "spoke to a vast audience", and "told us 'what lies behind the cloud'". However, those critical of it [^10][^11] suggest it fails to consider the viewpoint of those it depicts, and that is itself state-funded propaganda and "is part of the very problem the makers purport to deplore" [^12]. These critics also assert that "the makers set out with a preconceived objective" [^12], and that there was no attempt to understand what drove the protesters and consider both sides of the story. They say the documentary failed to ask an important question: "why so many people no longer trust the media". They say the mainstream media "have lost sight of what was previously their primary objective which, was to reflect society back to itself and report, as neutrally as possible, on matters of interest and concern to the communities they purported to serve" [^12].

Each of these two documentaries, Fire and Fury and River of Filth, depict a different perspective of the Wellington Protests. There are many differences in the production of each of the pieces. Firstly, the stuff documentary had significant funding, took significant time and effort to complete, and was backed by a large team of successful journalists [^10]. Conversely, the River of Filth had very little funding, and was made by a very small team. Despite this, both videos demonstrate the power of misinformation in our digital age.

I am not qualified to suggest what constitutes good journalism, however as a computer science student, I can consider the impact that our work as IT professionals has on the issue. 

# 3 - The spread of information
We live in an digital age. Vast amounts of Information is widely accessible to everyone. This is made possible by various websites and applications. Although the benefits of these technologies are great, they come with great responsibility. Not only do they provide a platform for individuals to access information, they also enable the spread of potentially harmful, false, and misleading information.

The spread of information has evolved. Articles show to users are carefully ranked by algorithms built into social media platforms such as Facebook [^13], and Twitter [^14]. Rather than show you each post in chronological order, algorithms consider the amount of engagement posts are getting, and show more popular posts higher up in viewers feeds, thus making them reach a larger audience. This helps to improve the experience of the viewers, as the posts they see will be of higher interest. However, by promoting content that receives a large amount of engagement, these algorithms have a tendency to promote controversial content. This is because controversial content creates a stronger emotional response in a viewer [^15]. Unfortunately, the algorithms are unable to determine whether engagement is from people sharing something because they dislike it or because they like it. Furthermore, there are many groups with the intent of creating hordes of fake accounts to spread a particular agenda and create controversy. This has been termed - "Coordinated Inauthentic Behaviour" within Facebook [^13].

Some social media sites such as Reddit and YouTube have employed some interesting, and sometimes effective, techniques to combat these issues.  The main ones being YouTube's dislike button and Reddit Karma system [^17]. On Reddit, this allows users to condemn posts that they believe are harmful, wrong, or contain misinformation. However, users can just as easily downvote posts simply because they disagree. YouTube however, recently removed the dislike count from videos but kept the dislike button. This was to combat a few issues, including hate campaigns against a particular channel is which groups would spam a channel with dislikes with the intent of damaging the channel [^18]. The YouTube community was outraged at this decision. Many users stated they relied on the dislike count to discern the authenticity and usefullness of a video before wasting time watching it.

# 4 - What can we do about it?
So what can we do, as IT professionals, to improve the online environemnt wit regard to the spread of information? The ACM code of ethics outlines a set of principles that should act as a baseline for our actions. The ACM code of ethics was "designed to inspire and guide the ethical conduct of all computing professionals" and act as a "basis for remediation when violations occur". The Code is a set of principles with the public good as the primary consideration, each with a set of guidelines to help professionals put the principles into practice. The Code is an attempt to apply fundamental ethical principles to the computing profession.

How can we apply this Code to the issue of misinformation, censorship, and freedom of expression. This is a very difficult and nuanced topic. I personally think that freedom of speech is a very important part of our lives and that it should be held in the highest regard. However, it is not possible to grant entirely free speech to everyone while completely prohibiting misinformation. We must find a trade-off between free speech and censorship of misinformation. As Mark Zuckerberg mention on episode 1863 of the Joe Rogan Experience podcast [^13], when identifying which channels should be censored, we have to choose between more false positives or more false negatives. It takes a substantial effort to fact-check and verify articles. For this reason, sites such as Facebook, make use of AI algorithms to flag potentially unwanted content [^13]. This has some inherent issues: Namely, how do these algorithms decide what is harmful? What data is it trained on? Who chose what to train the algorithms on?  Why should they be the ones to decide what is right and wrong? In the interview with Joe Rogan, Zuckerberg stated that for important and controversial cases, posts are reviewed by third parties which analyse and fact check these articles. This is still not a perfect solution. The decision about what is censored is still made by a select group of people. Maybe this is the best option, I cannot say for sure that it is not.

When the Voices for Freedom group grew sufficiently large, Facebook made the decision to ban them. Subsequently, they switched to using Telegram [^20] messenger and the Gab [^19] social network as their main platforms. These sites value free speech and individual liberty above all else. These sites have become a haven for the far-right and other fringe groups, many of which have been banned from mainstream sites such as Facebook and Twitter [^21][^22]. This is concerning because It is concentrating the misinformation spreaders, trolls, and conspiracy theorists in one large echo-chamber.

While it is not feasible to fully eliminate harmful media, there are ways in which we can protect our society against it. Firstly, we should place greater priority on educating people about misinformation, disinformation, and other harmful media, and suggest ways in which individuals can protect themselves. We should encourage people to do proper research and come to their own conclusions about controversial subjects. Unfortunately, this is very difficult when media, both mainstream and social, is so saturated with bad information and malignant organisations.

# Conclusion
In conclusion the anti-vax, anti-establishment protests in Wellington are a symptom of a larger problem within the online world. We live in an age where information is widely available and consumed by a large proportion of the world. This information is not always truthful, and is often intentionally misleading and/or harmful. Groups such as Voices for Freedom and Counterspin Media at the forefront of the Wellington protests are able to utilise these platforms, to further their agenda and reach a larger audience, regardless of the accuracy and truthfulness of their information. As IT professionals, our work plays an important role in this environment, and we have an obligation to consider the ethical implication of our actions. As stated in the ACM Code of Ethics, the public good, and human lives should be the primary factor informing our decisions. However, despite our best efforts, it is not possible to fully eradicate harmful misinformation, disinformation, and conspiracy theories without forfeiting our right to free speech.


# References
[^0]:https://www.acm.org/code-of-ethics
[^1]: https://www.alcor.org/library/persons-apparently-dead/
[^2]: https://en.wikipedia.org/wiki/2022_Wellington_protest
[^3]: https://www.stuff.co.nz/dominion-post/news/wellington/127928119/protesters-disperse-after-major-police-operation-ends-parliament-occupation
[^4]:  https://www.nzherald.co.nz/nz/wellington-protest-police-wont-stop-until-occupation-cleared-out-says-former-frontline-cop/RMVTC7A6FYGTJCHLNM36QDWDZM/
[^5]: https://www.theguardian.com/world/2021/aug/30/even-as-new-zealand-battles-covid-trust-in-government-bucks-global-trend
[^6]:https://89initiative.com/the-role-of-social-media-in-protests-mobilising-or-polarising/
[^7]:https://interactives.stuff.co.nz/2022/08/circuit/fire-and-fury-disinformation-in-new-zealand/
[^8]: https://www.imdb.com/title/tt21914900/
[^9]:https://www.stuff.co.nz/opinion/129689450/fire-and-fury-documentary-shows-journalism-at-the-peak-of-its-powers
[^10]:https://theplatform.kiwi/opinions/fire-and-fury-is-often-funny-unintentionally
[^11]: https://www.thedailyexaminer.co.nz/state-funded-fire-and-fury-documentary-unbalanced-hyperbole/
[^12]: https://karldufresne.blogspot.com/2022/08/a-few-thoughts-on-stuffs-fire-and-fury.html
[^13]:https://open.spotify.com/episode/51gxrAActH18RGhKNza598?si=c97b379af53445b9
[^14]:https://blog.hootsuite.com/twitter-algorithm/
[^15]:https://www.warc.com/newsandopinion/news/consumers-respond-to-emotional-content/en-gb/38426
[^16]:https://msafaksari.com/2022/02/28/fake-and-troll-accounts-on-social-media/
[^17]: https://www.reddithelp.com/hc/en-us/articles/204511829-What-is-karma-
[^18]:https://www.makeuseof.com/the-real-reason-why-youtube-hid-dislikes/
[^19]: https://gab.com
[^20]: https://telegram.org
[^21]: https://www.theguardian.com/media/2016/nov/17/gab-alt-right-social-media-twitter
[^22]: https://web.archive.org/web/20181031003944/https://www.bloomberg.com/news/articles/2018-10-30/gab-an-online-haven-for-white-supremacists-plots-its-future